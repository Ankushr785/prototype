{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.chdir('/home/fractaluser/Downloads/omega')\n",
    "from keras.layers import Input, Dense, Reshape, LSTM, RepeatVector\n",
    "from keras.models import Model\n",
    "from keras import callbacks\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = pd.read_csv('sample_simulated_transaction_history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>purchaseamount</th>\n",
       "      <th>dept</th>\n",
       "      <th>category</th>\n",
       "      <th>chain</th>\n",
       "      <th>purchasequantity</th>\n",
       "      <th>company</th>\n",
       "      <th>brand</th>\n",
       "      <th>productsize</th>\n",
       "      <th>productmeasure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donor_1</td>\n",
       "      <td>2015-03-04</td>\n",
       "      <td>203.174075</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Sports</td>\n",
       "      <td>site_1</td>\n",
       "      <td>1</td>\n",
       "      <td>Company1</td>\n",
       "      <td>Brand3</td>\n",
       "      <td>x</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donor_1</td>\n",
       "      <td>2016-04-17</td>\n",
       "      <td>300.639489</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Sports</td>\n",
       "      <td>site_1</td>\n",
       "      <td>1</td>\n",
       "      <td>Company1</td>\n",
       "      <td>Brand1</td>\n",
       "      <td>x</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donor_1</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>374.096413</td>\n",
       "      <td>Women Apparel</td>\n",
       "      <td>Dresses/Jumpsuits</td>\n",
       "      <td>site_1</td>\n",
       "      <td>1</td>\n",
       "      <td>Company2</td>\n",
       "      <td>Brand1</td>\n",
       "      <td>x</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Donor_1</td>\n",
       "      <td>2015-09-04</td>\n",
       "      <td>348.347601</td>\n",
       "      <td>Women Apparel</td>\n",
       "      <td>Dresses/Jumpsuits</td>\n",
       "      <td>site_1</td>\n",
       "      <td>1</td>\n",
       "      <td>Company2</td>\n",
       "      <td>Brand3</td>\n",
       "      <td>x</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donor_1</td>\n",
       "      <td>2016-03-08</td>\n",
       "      <td>287.477333</td>\n",
       "      <td>Women Apparel</td>\n",
       "      <td>Dresses/Jumpsuits</td>\n",
       "      <td>site_1</td>\n",
       "      <td>1</td>\n",
       "      <td>Company1</td>\n",
       "      <td>Brand3</td>\n",
       "      <td>x</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id        date  purchaseamount           dept           category  \\\n",
       "0  Donor_1  2015-03-04      203.174075         Sports             Sports   \n",
       "1  Donor_1  2016-04-17      300.639489         Sports             Sports   \n",
       "2  Donor_1  2015-04-06      374.096413  Women Apparel  Dresses/Jumpsuits   \n",
       "3  Donor_1  2015-09-04      348.347601  Women Apparel  Dresses/Jumpsuits   \n",
       "4  Donor_1  2016-03-08      287.477333  Women Apparel  Dresses/Jumpsuits   \n",
       "\n",
       "    chain  purchasequantity   company   brand productsize productmeasure  \n",
       "0  site_1                 1  Company1  Brand3           x             xx  \n",
       "1  site_1                 1  Company1  Brand1           x             xx  \n",
       "2  site_1                 1  Company2  Brand1           x             xx  \n",
       "3  site_1                 1  Company2  Brand3           x             xx  \n",
       "4  site_1                 1  Company1  Brand3           x             xx  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(939512, 11)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data.date = pd.to_datetime(sample_data.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_trunc(x):\n",
    "    x = \"_\".join(x.split(\"_\", 2)[:2])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data.id = sample_data.id.map(lambda x:name_trunc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "depts = []\n",
    "for i in sample_data.dept.unique():\n",
    "    df.append(sample_data[(sample_data.dept == i)].reset_index(drop = True)[['id','date', 'purchaseamount']])\n",
    "    depts.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_encoding(dataframe, depts, sample_data, pre_end_date, pre_start_date, EPOCHS, BATCH_SIZE, DIM):\n",
    "    complete_data = pd.DataFrame({'date':pd.date_range(sample_data.date.min(), sample_data.date.max())})\n",
    "    complete_data.set_index('date', inplace = True)\n",
    "    for i in df[0].id.unique():\n",
    "        specific_donor = df[0][(df[0].id == i)].reset_index(drop = True).groupby(['date']).max().drop(labels = ['id'], axis = 1).reindex(pd.date_range(sample_data.date.min(), sample_data.date.max()), fill_value = 0)\n",
    "        complete_data[i] = pd.DataFrame({i:specific_donor.purchaseamount})\n",
    "\n",
    "    xtrain = complete_data[pre_start_date:pre_end_date]\n",
    "    x_train = xtrain.T.values\n",
    "    xtrain1 = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "\n",
    "    encoding_dim = DIM\n",
    "\n",
    "    inputs = Input(shape=(xtrain1.shape[1], 1))\n",
    "    encoded = LSTM(encoding_dim)(inputs)\n",
    "\n",
    "    decoded = RepeatVector(xtrain1.shape[1])(encoded)\n",
    "    decoded = LSTM(1, return_sequences=True)(decoded)\n",
    "\n",
    "    sequence_autoencoder = Model(inputs, decoded)\n",
    "    encoder = Model(inputs, encoded)\n",
    "    \n",
    "    encoded_input = Input(shape=(None,encoding_dim))\n",
    "    decoder_layer = sequence_autoencoder.layers[-1]\n",
    "    decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "    sequence_autoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics = ['mae'])\n",
    "\n",
    "    history = sequence_autoencoder.fit(xtrain1, xtrain1, epochs=EPOCHS, verbose = 1, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                   callbacks = [callbacks.EarlyStopping(monitor='loss', patience=10, mode='auto')])\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.savefig('performance-%s.png' % depts)\n",
    "    \n",
    "    encoded_mat = encoder.predict(xtrain1)\n",
    "    new_df = pd.DataFrame(encoded_mat)\n",
    "    new_df[new_df<0] = 0\n",
    "    new_df.insert(loc=0, column='id', value=complete_data.columns.values)\n",
    "    \n",
    "    original = pd.DataFrame(x_train)\n",
    "    original.insert(loc = 0, column = 'id', value = complete_data.columns.values)\n",
    "    \n",
    "    encoded_mat = np.reshape(encoded_mat, (encoded_mat.shape[0], encoded_mat.shape[1], 1))\n",
    "    decoded_mat = decoder.predict(encoded_mat)\n",
    "    comparison_df = pd.DataFrame(decoded_mat)\n",
    "    comparison_df[comparison_df<0] = 0\n",
    "    comparison_df.insert(loc = 0, column = 'id', value = complete_data.columns.values)\n",
    "    \n",
    "    \n",
    "\n",
    "    return new_df, original, comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2617/2617 [==============================] - 14s 5ms/step - loss: 452.0110 - mean_absolute_error: 1.2801\n",
      "Epoch 2/1000\n",
      "2617/2617 [==============================] - 8s 3ms/step - loss: 451.7926 - mean_absolute_error: 1.3159\n",
      "Epoch 3/1000\n",
      "2617/2617 [==============================] - 10s 4ms/step - loss: 451.6284 - mean_absolute_error: 1.3695\n",
      "Epoch 4/1000\n",
      "2617/2617 [==============================] - 8s 3ms/step - loss: 451.4580 - mean_absolute_error: 1.4805\n",
      "Epoch 5/1000\n",
      "2617/2617 [==============================] - 8s 3ms/step - loss: 451.2720 - mean_absolute_error: 1.6492\n",
      "Epoch 6/1000\n",
      "2617/2617 [==============================] - 10s 4ms/step - loss: 451.1776 - mean_absolute_error: 1.7351\n",
      "Epoch 7/1000\n",
      "2617/2617 [==============================] - 9s 4ms/step - loss: 450.8845 - mean_absolute_error: 1.8610\n",
      "Epoch 8/1000\n",
      "2617/2617 [==============================] - 10s 4ms/step - loss: 450.8145 - mean_absolute_error: 1.9771\n",
      "Epoch 9/1000\n",
      "2617/2617 [==============================] - 9s 3ms/step - loss: 450.7464 - mean_absolute_error: 2.0462\n",
      "Epoch 10/1000\n",
      "2617/2617 [==============================] - 9s 3ms/step - loss: 450.6837 - mean_absolute_error: 2.0583\n",
      "Epoch 11/1000\n",
      "2617/2617 [==============================] - 10s 4ms/step - loss: 450.6316 - mean_absolute_error: 2.0429\n",
      "Epoch 12/1000\n",
      "2617/2617 [==============================] - 9s 3ms/step - loss: 450.5697 - mean_absolute_error: 2.0224\n",
      "Epoch 13/1000\n",
      "2617/2617 [==============================] - 9s 3ms/step - loss: 450.5238 - mean_absolute_error: 2.0063\n",
      "Epoch 14/1000\n",
      "2617/2617 [==============================] - 8s 3ms/step - loss: 450.4651 - mean_absolute_error: 1.9984\n",
      "Epoch 15/1000\n",
      "2617/2617 [==============================] - 8s 3ms/step - loss: 450.4154 - mean_absolute_error: 1.9983\n",
      "Epoch 16/1000\n",
      "2617/2617 [==============================] - 8s 3ms/step - loss: 450.3785 - mean_absolute_error: 2.0054\n",
      "Epoch 17/1000\n",
      "2617/2617 [==============================] - 8s 3ms/step - loss: 450.3206 - mean_absolute_error: 2.0112\n",
      "Epoch 18/1000\n",
      "2617/2617 [==============================] - 8s 3ms/step - loss: 450.2813 - mean_absolute_error: 2.0070\n",
      "Epoch 19/1000\n",
      "2617/2617 [==============================] - 8s 3ms/step - loss: 450.2462 - mean_absolute_error: 1.9967\n",
      "Epoch 20/1000\n",
      "2617/2617 [==============================] - 8s 3ms/step - loss: 450.2384 - mean_absolute_error: 1.9862\n",
      "Epoch 21/1000\n",
      "2617/2617 [==============================] - 8s 3ms/step - loss: 450.2365 - mean_absolute_error: 1.9826\n",
      "Epoch 22/1000\n",
      "2617/2617 [==============================] - 8s 3ms/step - loss: 450.2359 - mean_absolute_error: 1.9863\n",
      "Epoch 23/1000\n",
      "2617/2617 [==============================] - 8s 3ms/step - loss: 450.2358 - mean_absolute_error: 1.9884\n",
      "Epoch 24/1000\n",
      "2617/2617 [==============================] - 8s 3ms/step - loss: 450.2355 - mean_absolute_error: 1.9897\n",
      "Epoch 25/1000\n",
      "2617/2617 [==============================] - 8s 3ms/step - loss: 450.2353 - mean_absolute_error: 1.9917\n",
      "Epoch 26/1000\n",
      "2617/2617 [==============================] - 9s 3ms/step - loss: 450.2352 - mean_absolute_error: 1.9942\n",
      "Epoch 27/1000\n",
      "2617/2617 [==============================] - 8s 3ms/step - loss: 450.2351 - mean_absolute_error: 1.9947\n",
      "Epoch 28/1000\n",
      "2000/2617 [=====================>........] - ETA: 2s - loss: 406.8084 - mean_absolute_error: 1.8815"
     ]
    }
   ],
   "source": [
    "encod = []\n",
    "original = []\n",
    "compare = []\n",
    "pre_start_date = '2015-01-01'\n",
    "pre_end_date = '2016-01-01'\n",
    "for i in range(len(df)):\n",
    "    alpha, beta, gamma = obtain_encoding(df[i], depts[i], sample_data, pre_end_date, pre_start_date, EPOCHS=1000, BATCH_SIZE=500, DIM=50)\n",
    "    encod.append(alpha)\n",
    "    original.append(beta)\n",
    "    compare.append(gamma)\n",
    "    encod[-1].to_csv('encoding_of_%s_customers.csv' %depts[i], index = False)\n",
    "    original[-1].to_csv('original_of_%s_customers.csv' %depts[i], index = False)\n",
    "    compare[-1].to_csv('comparison_of_%s_customers.csv' %depts[i], index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
